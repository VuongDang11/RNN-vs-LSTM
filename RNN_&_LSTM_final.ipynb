{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "eimQ0VTlAF3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network (RNN)\n",
        "\n"
      ],
      "metadata": {
        "id": "DoWrkwOaAtTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "alZ5VH3BAyiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = pd.read_csv('/content/Google_Stock_Price_Train.csv')\n",
        "dataset_train.head()"
      ],
      "metadata": {
        "id": "IUqKXIGtAQH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dataset_train.loc[:, [\"Open\"]].values\n",
        "train"
      ],
      "metadata": {
        "id": "yBnZj9pCAf8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "train_scaled"
      ],
      "metadata": {
        "id": "bGIS7tHAArBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_scaled)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bueT3cDGA9td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_scaled))\n",
        "print(train_scaled.shape)"
      ],
      "metadata": {
        "id": "9FLsnrjUBULw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a data structure with 50 timesteps and 1 output\n",
        "X_train = []\n",
        "y_train = []\n",
        "timesteps = 50\n",
        "for i in range(timesteps, 1258):\n",
        "    X_train.append(train_scaled[i-timesteps:i, 0])\n",
        "    y_train.append(train_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "OLc6Wh5CBfn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train"
      ],
      "metadata": {
        "id": "pbxWT-aLBsqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "4Hy6UBTfB_ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN model"
      ],
      "metadata": {
        "id": "mXRxWRTVCBsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Initializing the RNN\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the first RNN layer and some Dropout regularisation\n",
        "model.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second RNN layer and some Dropout regularisation\n",
        "model.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third RNN layer and some Dropout regularisation\n",
        "model.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth RNN layer and some Dropout regularisation\n",
        "model.add(SimpleRNN(units = 50))\n",
        "model.add(Dropout(0.2)) # Avoid overfitting\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z0Dxw6QsCEJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction the test model"
      ],
      "metadata": {
        "id": "JeMhZuB5DYEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the real stock price of 2017\n",
        "dataset_test = pd.read_csv('/content/Google_Stock_Price_Test.csv')\n",
        "dataset_test.head()"
      ],
      "metadata": {
        "id": "4JiYDNY2Dbzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_stock_price = dataset_test.loc[:, [\"Open\"]].values\n",
        "real_stock_price"
      ],
      "metadata": {
        "id": "n4tXdHDQCFah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the prediction of stock price of 2017\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
        "dataset_total"
      ],
      "metadata": {
        "id": "4luTbJ4WEE9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1) # Reshapes the 1D Numpy array into a 2D array\n",
        "inputs = scaler.transform(inputs)  # min max scaler\n",
        "inputs"
      ],
      "metadata": {
        "id": "wLzdAi96ESRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "7JvXMVwGEvcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "for i in range(timesteps, 70):\n",
        "  X_test.append(inputs[i - timesteps:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = model.predict(X_test)\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
        "\n",
        "# Visualizing Results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HKe_u9DQEwr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Long Short-Term Memory (LSTM)"
      ],
      "metadata": {
        "id": "Ilputrq30FA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('/content/Google_Stock_Price_Train.csv')\n",
        "data_test = pd.read_csv('/content/Google_Stock_Price_Test.csv')\n"
      ],
      "metadata": {
        "id": "kk83HhEW0J7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "_6J2QuOd0rU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = data_train.loc[:, [\"Open\"]].values\n",
        "train_set"
      ],
      "metadata": {
        "id": "DZMXdu0p0rAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "minmax_scale = MinMaxScaler(feature_range=(0,1))\n",
        "train_set_scaled = minmax_scale.fit_transform(train_set)\n",
        "train_set_scaled"
      ],
      "metadata": {
        "id": "kvcvhVnz1G0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences with lockback windown\n",
        "X_train = []\n",
        "y_train = []\n",
        "timesteps = 50\n",
        "\n",
        "for i in range(timesteps, 1258):\n",
        "    X_train.append(train_set_scaled[i-timesteps:i, 0])\n",
        "    y_train.append(train_set_scaled[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "65ySzQEI1RP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to 3D: (samples, timesteps, features)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train"
      ],
      "metadata": {
        "id": "HUrD_piU14P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "JROVpOSI2pFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RQpNybMF2qRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a dummy model_lstm to make predictions\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(units=1))\n",
        "\n",
        "# Compile the model_lstm\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model_lstm\n",
        "print(\"Training the model_lstm...\")\n",
        "history = model_lstm.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n"
      ],
      "metadata": {
        "id": "tK1__yW_2sgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xOsb2qa130k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction the test model"
      ],
      "metadata": {
        "id": "va2tfnnn4xYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the real stock price of 2017\n",
        "dataset_test = pd.read_csv('/content/Google_Stock_Price_Test.csv')\n",
        "dataset_test.head()"
      ],
      "metadata": {
        "id": "-DiF3rN24zCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_stock_price = dataset_test.loc[:, [\"Open\"]].values\n",
        "real_stock_price"
      ],
      "metadata": {
        "id": "MHTkoMsx9097"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the predidtion of stock in 2017\n",
        "dataset_total = pd.concat((data_train['Open'], data_test['Open']), axis = 0)\n",
        "dataset_total\n"
      ],
      "metadata": {
        "id": "L1zSeHwr91rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_lstm = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1) # Reshapes the 1D Numpy array into a 2D array\n",
        "inputs_lstm = scaler.transform(inputs_lstm)  # min max scaler\n",
        "inputs_lstm"
      ],
      "metadata": {
        "id": "EMoeakZq5U4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "for i in range(timesteps, len(inputs_lstm)):\n",
        "  X_test.append(inputs_lstm[i - timesteps:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Making predictions\n",
        "predicted_stock_price = model_lstm.predict(X_test)\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)"
      ],
      "metadata": {
        "id": "oSOmGlzI7EcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MdBD2YwP8Swb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ploty with Zoom In/Out"
      ],
      "metadata": {
        "id": "fyFWX0ICgX-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install plotly ipywidgets"
      ],
      "metadata": {
        "id": "64vE780UgZco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager() # This enable will make ipywidgets work nicely\n",
        "import plotly.graph_objects as go\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "fo6Tny-xgtLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure proper dtypes and tidy ordering\n",
        "data_train[\"Date\"] = pd.to_datetime(data_train[\"Date\"], errors=\"coerce\")\n",
        "data_train[\"Open\"] = pd.to_numeric(data_train[\"Open\"], errors=\"coerce\")\n",
        "\n",
        "# Drop bad rows, sort, reset index\n",
        "data_train = data_train.dropna(subset=[\"Date\", \"Open\"]).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# Optional: ensure business-day cadence and fill gaps (safer for markets)\n",
        "bidx = pd.date_range(data_train[\"Date\"].min(), data_train[\"Date\"].max(), freq=\"B\")\n",
        "data_train = (data_train\n",
        "              .set_index(\"Date\")\n",
        "              .reindex(bidx))\n",
        "data_train[\"Open\"] = data_train[\"Open\"].ffill().bfill()\n",
        "data_train = data_train.rename_axis(\"Date\").reset_index()\n",
        "\n",
        "# Final sanity check\n",
        "assert data_train[\"Date\"].notna().all() and data_train[\"Open\"].notna().all()\n",
        "print(\"✅ Data ready. Rows:\", len(data_train))\n"
      ],
      "metadata": {
        "id": "pSXjNJO6mNBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    scaler_y  # if you created it during training\n",
        "except NameError:\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler_y = MinMaxScaler().fit(data_train[\"Open\"].values.reshape(-1,1))\n"
      ],
      "metadata": {
        "id": "-_RB24vSo3o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose model"
      ],
      "metadata": {
        "id": "0cyPwIYknv8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_lstm # should display a Keras model summary repr\n",
        "\n",
        "lookback = model.input_shape[1]\n",
        "n_features = model.input_shape[2]\n",
        "assert n_features == 1, \"This block assumes a univariate model (only 'Open'). If multivariate, see notes below.\"\n",
        "print(\"lookback:\", lookback, \"  n_features:\", n_features)"
      ],
      "metadata": {
        "id": "KxBGtJconxAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _last_lookback_window_univariate(series: pd.Series):\n",
        "    \"\"\"Scale 'Open' and return last (1, lookback, 1) window.\"\"\"\n",
        "    scaled = scaler_y.transform(series.values.reshape(-1,1))\n",
        "    return scaled[-lookback:].reshape(1, lookback, 1)\n",
        "\n",
        "def forecast_next_open(n_days: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Iterative one-step-ahead forecast of Open for next n_days (business days).\n",
        "    Returns DataFrame with Date, Predicted (in original price units).\n",
        "    \"\"\"\n",
        "    # Future dates (business days)\n",
        "    # Take the last days\n",
        "    # Create future business days (except weekend)\n",
        "    last_date = data_train[\"Date\"].max()\n",
        "    future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=n_days, freq=\"B\")\n",
        "\n",
        "    # Seed window from the last lookback Open prices\n",
        "    window = _last_lookback_window_univariate(data_train[\"Open\"])\n",
        "\n",
        "    preds_scaled = []\n",
        "    for _ in range(n_days):\n",
        "      # Predict the next days with the scaled of Open Price (1, 1)\n",
        "        yhat_scaled = model.predict(window, verbose=0)  # (1,1)\n",
        "        preds_scaled.append(yhat_scaled[0,0])\n",
        "        # roll window forward and append the new prediction\n",
        "        window = np.concatenate([window[:,1:,:], yhat_scaled.reshape(1,1,1)], axis=1)\n",
        "    # Scaled all the prediction into [0, 1] shapes\n",
        "    # use inverse_transform to map them back to the Original Price Sale\n",
        "    preds = scaler_y.inverse_transform(np.array(preds_scaled).reshape(-1,1)).ravel()\n",
        "    return pd.DataFrame({\"Date\": future_dates, \"Predicted\": preds})\n"
      ],
      "metadata": {
        "id": "Mj1_QIernyh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ploty with Silder"
      ],
      "metadata": {
        "id": "WLk_B3b3pBqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slider = widgets.IntSlider(value=7, min=1, max=30, step=1, description=\"Days:\")\n",
        "output_box = widgets.Output()\n",
        "\n",
        "def plot_open_with_slider(n_days: int):\n",
        "    with output_box:\n",
        "        output_box.clear_output(wait=True)\n",
        "        fut = forecast_next_open(n_days)\n",
        "\n",
        "        fig = go.Figure()\n",
        "        # history (Open)\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=data_train[\"Date\"], y=data_train[\"Open\"],\n",
        "            name=\"History (Open)\", mode=\"lines\"))\n",
        "\n",
        "        # forecast line\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=fut[\"Date\"], y=fut[\"Predicted\"],\n",
        "            name=f\"Forecast +{n_days}d\", mode=\"lines+markers\"))\n",
        "\n",
        "        # Vertical boundary as shape (avoids datetime annotation bugs)\n",
        "        cutoff_dt = pd.to_datetime(data_train[\"Date\"].max()).to_pydatetime()\n",
        "        fig.add_shape(type=\"line\", x0=cutoff_dt, x1=cutoff_dt, y0=0, y1=1,\n",
        "                      xref=\"x\", yref=\"paper\", line=dict(dash=\"dot\"))\n",
        "        fig.add_annotation(x=cutoff_dt, y=1, xref=\"x\", yref=\"paper\",\n",
        "                           text=\"Forecast start\", showarrow=False, yshift=10)\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Open price forecast: next {n_days} business days\",\n",
        "            xaxis_title=\"Date\", yaxis_title=\"Open Price\",\n",
        "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "            margin=dict(l=0, r=0, t=60, b=0),\n",
        "        )\n",
        "        fig.update_xaxes(type=\"date\")\n",
        "        fig.show()\n",
        "\n",
        "widgets.interact(plot_open_with_slider, n_days=slider)\n",
        "display(output_box)\n"
      ],
      "metadata": {
        "id": "Go_Ix7LnoopN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monte Carlo Dropout\n"
      ],
      "metadata": {
        "id": "TDvYhPuWrTdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CI (confidence interval): uncertainty of the mean line itself. Narrower.\n",
        "\n",
        "##  PI (prediction interval): uncertainty of the actual future value (mean + randomness/volatility). Wider. => Recommended in Stock"
      ],
      "metadata": {
        "id": "LLQ9k1AbrXrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confidence Interval ( CI )\n",
        "# Prediction Interval ( PI )\n",
        "def forecast_open_mc_dropout(n_days: int, T: int = 100, conf: float = 0.95):\n",
        "    \"\"\"\n",
        "    Monte Carlo Dropout iterative forecast.\n",
        "    Returns DataFrame with Date, Mean, CI_Lower, CI_Upper, PI_Lower, PI_Upper.\n",
        "    \"\"\"\n",
        "    # future dates\n",
        "    last_date = data_train[\"Date\"].max()\n",
        "    future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=n_days, freq=\"B\")\n",
        "\n",
        "    # seed window\n",
        "    def seed():\n",
        "        scaled = scaler_y.transform(data_train[\"Open\"].values.reshape(-1,1))\n",
        "        return scaled[-lookback:].reshape(1, lookback, 1)\n",
        "\n",
        "    # T stochastic path (Dropout activate)\n",
        "    paths_scaled = []\n",
        "    for _ in range(T):\n",
        "        w = seed()\n",
        "        seq = []\n",
        "        for _ in range(n_days):\n",
        "            # IMPORTANT: call the model with training=True to keep dropout on\n",
        "            yhat_scaled = model(w, training=True).numpy()   # shape (1,1)\n",
        "            seq.append(yhat_scaled[0,0])\n",
        "            w = np.concatenate([w[:,1:,:], yhat_scaled.reshape(1,1,1)], axis=1)\n",
        "        paths_scaled.append(seq)\n",
        "\n",
        "    paths_scaled = np.array(paths_scaled)           # (T, n_days)\n",
        "    # inverse transform each path to price units\n",
        "    paths = scaler_y.inverse_transform(paths_scaled.reshape(-1,1)).reshape(T, n_days)\n",
        "\n",
        "    # Statistics per horizon\n",
        "    mean = paths.mean(axis=0)\n",
        "    std = paths.std(axis=0)\n",
        "\n",
        "    # 95% CI for the mean prediction at each horizon\n",
        "    z = 1.96 # for 95% of data lies with +-1.96 standard normal distribution\n",
        "    ci_lower = mean - z * (std / np.sqrt(T))\n",
        "    ci_upper = mean + z * (std / np.sqrt(T))\n",
        "\n",
        "    # 95% PI for individual outcomes — percentile-based across paths\n",
        "    # 95% Prediction Interval\n",
        "    pi_lower = np.percentile(paths, 2.5, axis=0)\n",
        "    pi_upper = np.percentile(paths, 97.5, axis=0)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"Date\": future_dates,\n",
        "        \"Mean\": mean,\n",
        "        \"CI_Lower\": ci_lower, \"CI_Upper\": ci_upper,\n",
        "        \"PI_Lower\": pi_lower, \"PI_Upper\": pi_upper\n",
        "    })\n"
      ],
      "metadata": {
        "id": "-PZX7rBCrXVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Widgets & Plot --------\n",
        "days_slider = widgets.IntSlider(value=7, min=1, max=30, step=1, description=\"Days:\")\n",
        "# Prediction the possible futures between 100 and 300\n",
        "T_slider    = widgets.IntSlider(value=100, min=20, max=150, step=20, description=\"MC runs:\")\n",
        "conf_dd     = widgets.Dropdown(\n",
        "    options=[(\"80%\",0.80),(\"90%\",0.90),(\"95%\",0.95),(\"99%\",0.99)],\n",
        "    value=0.95, description=\"Confidence:\"\n",
        ")\n",
        "output_box  = widgets.Output()"
      ],
      "metadata": {
        "id": "1POkpmQ3teot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot with CI and PI"
      ],
      "metadata": {
        "id": "eiYJccsztgCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_open_mc(n_days: int, T: int, conf: float):\n",
        "    with output_box:\n",
        "        output_box.clear_output(wait=True)\n",
        "        fut = forecast_open_mc_dropout(n_days=n_days, T=T, conf=conf)\n",
        "\n",
        "        # --- PLOT ---\n",
        "        fig = go.Figure()\n",
        "        # history\n",
        "        fig.add_trace(go.Scatter(x=data_train[\"Date\"], y=data_train[\"Open\"],\n",
        "                                 name=\"History (Open)\", mode=\"lines\"))\n",
        "        # mean line\n",
        "        fig.add_trace(go.Scatter(x=fut[\"Date\"], y=fut[\"Mean\"],\n",
        "                                 name=f\"Mean forecast (+{n_days}d)\", mode=\"lines+markers\"))\n",
        "\n",
        "        # CI band (mean uncertainty) – usually narrow\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=fut[\"Date\"], y=fut[\"CI_Upper\"],\n",
        "            mode=\"lines\", line=dict(width=0),  # invisible line\n",
        "            showlegend=False\n",
        "        ))\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=fut[\"Date\"], y=fut[\"CI_Lower\"],\n",
        "            name=f\"{int(conf*100)}% CI (mean)\",\n",
        "            mode=\"lines\", line=dict(width=0),\n",
        "            fill=\"tonexty\", fillcolor=\"rgba(200,100,255,0.3)\"  # purple shade\n",
        "        ))\n",
        "\n",
        "        # PI band (actuals uncertainty) – wider\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=fut[\"Date\"], y=fut[\"PI_Upper\"],\n",
        "            mode=\"lines\", line=dict(width=0),\n",
        "            showlegend=False\n",
        "        ))\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=fut[\"Date\"], y=fut[\"PI_Lower\"],\n",
        "            name=f\"{int(conf*100)}% PI (actual)\",\n",
        "            mode=\"lines\", line=dict(width=0),\n",
        "            fill=\"tonexty\", fillcolor=\"rgba(100,200,255,0.3)\"  # blue shade\n",
        "        ))\n",
        "\n",
        "        # Forecast boundary (robust datetime method)\n",
        "        cutoff_dt = pd.to_datetime(data_train[\"Date\"].max()).to_pydatetime()\n",
        "        fig.add_shape(type=\"line\", x0=cutoff_dt, x1=cutoff_dt, y0=0, y1=1,\n",
        "                      xref=\"x\", yref=\"paper\", line=dict(dash=\"dot\"))\n",
        "        fig.add_annotation(x=cutoff_dt, y=1, xref=\"x\", yref=\"paper\",\n",
        "                           text=\"Forecast start\", showarrow=False, yshift=10)\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Open forecast with CI & PI (MC Dropout, T={T}, {int(conf*100)}%)\",\n",
        "            xaxis_title=\"Date\", yaxis_title=\"Open Price\",\n",
        "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "            margin=dict(l=0, r=0, t=60, b=0),\n",
        "        )\n",
        "        fig.update_xaxes(type=\"date\")\n",
        "        fig.show()\n",
        "\n",
        "ui = widgets.VBox([days_slider, T_slider, conf_dd])\n",
        "out = widgets.interactive_output(plot_open_mc, {\"n_days\": days_slider, \"T\": T_slider, \"conf\": conf_dd})\n",
        "\n",
        "display(ui, output_box)"
      ],
      "metadata": {
        "id": "m07d9b7ssYBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMEpdFFis0e5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}